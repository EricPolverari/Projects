{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Create a JSON File of Your Credentials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. Please create your own credential JSON file in the current directory.\n",
    "\n",
    "    At first, you need to create a dictionary of your credentials.\n",
    "\n",
    "    Second, you need to create a JSON file (i.e. twitter_credentials.json) of your credentials.\n",
    "\n",
    "'''\n",
    "\n",
    "# note: you need to import json module at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = {\n",
    "    \"API_KEY\" : \"jY8Hi08PLldpy6wFjClEdGG7f\",\n",
    "    \"API_SECRET\" : \"43lCvI38e82ChtqR5ys1g7MVwYJZP9L3qYdn8Cm89XQEndX87w\",\n",
    "    \"ACCESS_TOKEN\" :  \"1449623905455378435-4QAuVmYZBrXdzXW7K1vwuc3hWkCE9I\",\n",
    "    \"ACCESS_TOKEN_SECRET\" : \"XC5jKjWzRPn1tDRei8kkMFC8OP8hLSXCGGNPAXk4tpfTw\"\n",
    "}\n",
    "\n",
    "credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = open('twitter_credentials.json', 'w')\n",
    "json.dump(credential, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('twitter_credentials.json', 'r')\n",
    "credentials = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your own app to get consumer key and secret\n",
    "API_KEY = credentials['API_KEY']\n",
    "API_SECRET = credentials['API_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twython(API_KEY, API_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Collect 1K Tweets of Your Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2. Please choose your own keyword to collect 1K tweets.\n",
    "\n",
    "    Please collect 1K tweets. Please use a code in Data_Collection_Twitter_API.ipynb\n",
    "    \n",
    "    You will have \"tweet_stream_KEYWORD_1000.json\" in your working folder. \n",
    "'''\n",
    "\n",
    "# note: 'KEYWORD' refers to your own keyword that you input in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from twython package import TwythonStreamer module\n",
    "from twython import TwythonStreamer\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# set a container to append 1000 tweets\n",
    "container = []\n",
    "\n",
    "# we are inheriting from TwythonStreamer class\n",
    "class MyStream(TwythonStreamer):\n",
    "    '''our own subclass of TwythonStreamer'''\n",
    "\n",
    "    # overriding\n",
    "    def on_success(self, data):\n",
    "        if 'text' in data:\n",
    "            print(data['text'])\n",
    "            # append tweets to the container\n",
    "            container.append(data)\n",
    "\n",
    "        # if you get enough tweets (e.g. 100), store it into JSON file and disconnect API.\n",
    "        if len(container) == 1000:\n",
    "            self.store_json()\n",
    "            self.disconnect()\n",
    "            \n",
    "    # overriding\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code)\n",
    "        self.disconnect()\n",
    "        \n",
    "    # our new method to store tweets into JSON file\n",
    "    def store_json(self):\n",
    "        infile = open('tweet_stream_{}_{}.json'.format(keyword, len(container)), 'w')\n",
    "        json.dump(container, infile)\n",
    "        infile.close()\n",
    "\n",
    "# read your Twitter credentials from your json file and assign them to variables\n",
    "infile = open('twitter_credentials.json')\n",
    "credentials = json.load(infile)\n",
    "infile.close()\n",
    "    \n",
    "API_KEY = credentials['API_KEY']\n",
    "API_SECRET = credentials['API_SECRET']\n",
    "ACCESS_TOKEN = credentials['ACCESS_TOKEN']\n",
    "ACCESS_TOKEN_SECRET = credentials['ACCESS_TOKEN_SECRET']\n",
    "\n",
    "# Twitter Streaming API needs all four credentials\n",
    "stream = MyStream(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# we will set a keyword\n",
    "keyword = \"NFL\"\n",
    "\n",
    "# time to collect 1000 tweets of the keyword\n",
    "stream.statuses.filter(track = keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Read JSON file for Prelinimary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3. Please read your JSON file (i.e. tweet_stream_KEYWORD_1000.json);\n",
    "    and assign it to \"data\" variable.\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "infile = open('tweet_stream_NFL_1000.json')\n",
    "data = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4. What are the ten most popular hashtags (#hashtag)?\n",
    "\n",
    "'''\n",
    "\n",
    "# note: you need to import Counter object from collections module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('tweet_stream_NFL_1000.json')\n",
    "data = json.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_list = []\n",
    "for t in data:\n",
    "    for h in t['entities']['hashtags']:\n",
    "        if h != []:\n",
    "            hashtag_list.append(h['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(hashtag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(hashtag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5. Who is the most fequently tweeting person about the topic?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "for t in data:\n",
    "    if t != '':\n",
    "        name_list.append(t['user']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Create Word Cloud from Your 1K Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6. Please (1) read your JSON file (i.e. tweet_stream_KEYWORD_1000.json), and assign it to \"contents\" variable,\n",
    "           (2) generate a word cloud image from the \"contents\" variable.\n",
    "           \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#(1) Open the JSON file and create a string variable, content\n",
    "infile = open('tweet_stream_NFL_1000.json')\n",
    "contents = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "data =''\n",
    "\n",
    "for t in contents:\n",
    "    data += t['text'] + '\\n'\n",
    "        \n",
    "#(2) Generating a word cloud image\n",
    "wordcloud = WordCloud(max_font_size=80, collocations = False).generate(data) # setting lower max_font_size to 80\n",
    "\n",
    "#(3) Display the generated image:\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q7. Plesae (1) display the generated word cloud image and\n",
    "           (2) save the image as wordcloud_new.pdf\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#(1) Open the JSON file and create a string variable, content\n",
    "infile = open('tweet_stream_NFL_1000.json')\n",
    "contents = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "data =''\n",
    "\n",
    "for t in contents:\n",
    "    data += t['text'] + '\\n'\n",
    "        \n",
    "#(2) Generating a word cloud image\n",
    "wordcloud = WordCloud(max_font_size=80, collocations = False).generate(data) # setting lower max_font_size to 80\n",
    "\n",
    "#(3) Display the generated image:\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud_new.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
